,Title,Post,Upvotes,Upvote_ratio,Created_date,Link,User
0,How do I get away from devops,"Iv been a DE for around 5 years now. I love working with data, building pipelines, ML platforms, supporting BI/DA/DS teams, etc. But I HATE dev ops.

I work for a company with a pretty complex cloud environment setup. Handling permissions and networking between microservices takes up about 80% of my daily energy.

It seems like a lot of DE jobs require quite a bit of devops work. Is this true?

How do I transition to a role that focuses less on devops and more on software design/performance? Iv been thinking of Skilling up and trying to transition into an ML. Engineer role. Would a role like that theoretically have less devops responsibility?",49,0.99,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16ysjx8/how_do_i_get_away_from_devops/,burns_after_reading
1,Is Polaris worth learning over pyspark? Or is it just hype while the industry has no intention of moving away from a Apache/Cloud framework,"I’ve been reading a lot about polars but one thing about the industry I’ve seen is that new technologies come and have a a lot of hype but do not cause any real change to the current accepted stack. 

I’m wondering if this subreddit feels the same way about it as me. Obviously it’s good to keep learning but between getting better at pyspark vs Polars I’m wondering which should be the focus",26,0.86,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yx6f1/is_polaris_worth_learning_over_pyspark_or_is_it/,richhoods
2,Failing to see impact and progression in DE,"So I’ve been working as a DE for 1.5 years. I’ve touched on some cloud, some ci/cd, lots of ETL and some database design. I enjoy the work but it seems to me that each DE job is sort of like this. Is this it? Do I just make pipelines until I hit senior or manager or am I missing something? Like there’s always work to be done and although we implement interesting solutions, no one really cares instead they ask for delivery dates or why the data is wrong. I’ve seen this across 2 teams, does DE not get recognition? 

Like I enjoy the work day to day but when I look at what I do or am creating, it just doesn’t seem impactful compared to other SWE roles like cloud/security/infra. 

I’m looking to switch jobs and next job will be more analytics focused (tableau/ETL). After working though I don’t know what my progression will be, like what does a senior / engineer manager in data do? How do I get there? Is it fulfilling?

It’s a loaded question I’m mainly just concerned about the culture &amp; future of DE work and if I made the right choice doing this after graduating with a CS degree.

I’m based in Toronto if that helps",15,0.95,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yhc5t/failing_to_see_impact_and_progression_in_de/,Big-Comparison321
3,Advice on Azure Data Engineering,"Hi,

I've built a data pipeline using an orchestrated azure function that has 5 or so steps (python scripts) that load data from a storage blob, perform a bunch of transformations on the data then load into an azure SQL database. I'm running into problems as I'm hitting the 10minute limit.

On top of this I'd also like to host and schedule a whole bunch of web scrapers (which would also probably hit the 10minute limit)

I'm looking at alternatives whilst staying within the Azure ecosystem. Currently I'm thinking of getting an Azure VM and installing airflow/prefect to run and manage this pipeline. The VM would also host and run the web scrapers.

Are there any other solutions you can recommend or anything I'm missing?",12,0.93,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yo0lc/advice_on_azure_data_engineering/,lieutenant_lowercase
4,How much time do you study each day?,"I have been working as a big data engineer for 5 years, and every day I realize that the topics are too broad and complex. I often get lost and don't know what to study in depth.

Do you have any advice on how to become a good data engineer?
How many books do you read in a year?
How many hours a day do you study? (Outside of working hours).

Any advice is welcome, thanks in advance",12,0.84,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z4nwt/how_much_time_do_you_study_each_day/,el_cortezzz
5,Is it typical to see Data Engineer and Data Science duties intertwined on Internship roles with smaller companies?,"Hey there, so ive been on the internship hunt for quite a long time now and 2 of the 3 interviews I've managed to get thus far I've wound up getting surprised with a surprising amount of DS questions (stats, ML modeling experience, prior work with DS/ML tools) along with typical SQL + Data Modeling, Python, Data Integration/Orchestration tooling questions.

The thing is this hasn't always been very explicit in the job posting and I've only really taken intro-level coursework in stats and ML (almost entirely intro-level supervised learning concepts and models, lightly touched unsupervised learning at the end) so I'm very weak footed when answering DS questions that go much further beyond basic regression in complexity. Im now wondering if I need to sit down and spend time improving that side of my skillset?

Its also extra stressful because doing an internship is a mandatory part of my undergrad program to graduate and with how brutally slim job postings are on average I cant afford to keep slipping on these interviews",8,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yx85g/is_it_typical_to_see_data_engineer_and_data/,Anic135
6,How to efficiently load ~20 TiB of weather data into a new PostgresSQL database? Is PostgresSQL even a good option?,"Hi everyone,

I should preface this by saying I'm a complete noob but I'd like to learn about relational databases and SQL.

I'm playing around with ""historical weather data"" produced by ERA5 which provides e.g. hourly temperatures globally at 0.25 degree resolution. The problem is that the data stretches back to 1940 so that's roughly (83 years) * (24*365 hours per year) * (360/0.25 * 180/0.25 grid points) = 754 billions rows per variable.

I'm finding it very slow to copy the data into Postgres even using: https://www.psycopg.org/psycopg3/docs/basic/copy.html#writing-data-row-by-row

I thought PostgresSQL might be a good option, possibly with PostGIS and/or TimescaleDB, but thought I'd start with just Postgres.

Am I taking a bad approach here? Should I consider another kind of database? Or am I just not loading my data in properly?

I'm also worried Postgres won't compress this data well, but haven't played around with this yet (might be where TimescaleDB helps?).

Thank you so much for any advice you guys might have!",8,0.84,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z8h6l/how_to_efficiently_load_20_tib_of_weather_data/,DeadDolphinResearch
7,Centrally documenting data flows of a BI product,"I have been tasked with centrally documenting a BI product and I am wondering how professionals approach this problem as I am relatively new to this field of work.

This product in short boils down to: get data from source system --&gt; select and transform data in SQL --&gt; store created tables in data warehouse --&gt; load in Power BI.

Of course there is a number of standard approaches in place such as commenting the SQL queries etc. but I am trying to find the best way to centrally store all underlying relationships in this data product. Such that for every Power BI measure, I store the used data warehouse column(s) and the source column(s) used to generate said data warehouse column(s).

I attached a visual example of the relationships I am trying to centrally document, quickly written up in MS Excel style. In the example *my\_powerbi\_measure\_1* is created using *my\_datawarehouse\_column1*/*2*/*3* and *my\_datawarehouse\_column1* is created using *my\_sourcedata\_column1*.

&amp;#x200B;

What are tools or documentation approaches you guys use, or would use, to get to this central documentation of data flows? All ideas and tips are appreciated!

&amp;#x200B;

[Visual example](https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;format=png&amp;auto=webp&amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3)",5,0.86,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yuq2k/centrally_documenting_data_flows_of_a_bi_product/,basr98
8,Lambda to Firehose vs directly to S3,"I'm pulling data from a realtime feed at the moment, about 200k records and then pushing them to a Kinesis Data Firehose.  I've experimented with batch sizes and the like, but at the moment I'm seeing that the 200k records when serialised is about 20MB, and the batch and write to disk as parquet via KDF is taking a couple of minutes.  


The realtime feed is updated every 15 seconds, but I'm so far unable to ingest at that rate, so I've dialled it back to every 2 minutes for the time being.

Currently the task is billed for Lambda, KDF and S3.

I've been experimenting and using Polars to make the 200k records into a dataframe and then writing it directly to S3. It takes about 15 seconds and the parquet file is about 700kb. It's light years faster and cheaper than KDF and I can run it at a faster rate than the KDF.

The overhead is Lambda and S3.  


Now I understand that if you can't afford to drop/loose any of the data, then you need to have a data stream manager of some flavour, but why is it so much slower and so much more expensive?  


I'm missing something in regards to the sweet-spot for using the product.",5,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z5j8q/lambda_to_firehose_vs_directly_to_s3/,Comfortable_Fee5361
9,"AWS: CDC using DMS, Kinesis &amp; Lambda with Dynamic SQL","I have published a medium article about a dynamic Database CDC Data Processing pipeline in AWS which we designed in one of my earlier projects. Thought it would be useful for someone who faced similar challenges.

Please take a look and let me know if the logic &amp; wording are clear, as the code is out of scope

[https://medium.com/@sarath.mec/aws-dynamic-cdc-migration-using-dms-kinesis-and-lambda-d0ae8abff76f](https://medium.com/@sarath.mec/aws-dynamic-cdc-migration-using-dms-kinesis-and-lambda-d0ae8abff76f)[https://medium.com/@sarath.mec/kinesis-lambda-trigger-dlq-reprocessing-using-aws-glue-cb0a62710a84](https://medium.com/@sarath.mec/kinesis-lambda-trigger-dlq-reprocessing-using-aws-glue-cb0a62710a84)",3,0.81,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z0rp5/aws_cdc_using_dms_kinesis_lambda_with_dynamic_sql/,DragonflyHumble
10,"I’m a software engineer, I want to be a DS or DE. What should I do?","Hello everyone. I’m a recent grad, i’ve been working as a SE for about 4 months now(first career job). The company is good but i dont see myself here long term because of the location, I had to move away. I graduated with a BS in information systems and have knowledge of SQL, tableau, power Bi and most of all python(I use it at work everyday). With SQL, Power Bi and tableau, i had a bunch of data analysis courses. In about 5 months if I wanted to switch jobs to a more entry level Data focused role, could I just apply or would i need something to make me look more attractive to companies? Like maybe get my masters in DS(i want to at some point) or some certificates, is that necessary?

Basically should i just go ahead and apply or am i wasting my time going up that route as i am now?",3,0.8,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z055o/im_a_software_engineer_i_want_to_be_a_ds_or_de/,ShowtimeCharles
11,Next Step as Senior DE vs Senior DataOps,"Hi All,

I am a data engineer with 5 years of experience. I have got an offer for Senior DataOps and am applying for other Senior DE roles. 

The DataOps role primarily comprises of supporting systems and DE teams and creating alerts for the existing pipelines. It is a support job. 

I am confused if this is the right path to take for my next Data Engineering role. Does going ahead with this restrict me to SRE/DevOps role?

It will be very helpful if you guys can give me some advice on this, if I should take it up or not? And would I get stuck in this and can I, in the future be eligible for Data Engineering roles?",3,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yzsxa/next_step_as_senior_de_vs_senior_dataops/,ParticularDear5826
12,having a hard time self-studying kafka,"Hi all, I currently know how to do basic batch-processing ETL (have tried extracting data from APIs and gsheets using python, used GCS / AWS S3 buckets to store raw and transformed data if needed, and ingest to bigquery (I find that redshift is too expensive for personal projects so I just stick to bigquery), using airflow for orchestration, docker compose to setup airflow, all inside a headless VM, port passthrough so I can access airflow web UI in my browser).

Now i want to learn streaming ETL using kafka and pyspark. I find it difficult to setup a self-managed kafka cluster as you have to learn so many new things at once, at the same time I don't think it's gonna be cheap to rely on GCP / AWS for kafka (this is my understanding, please correct me if I'm wrong). There's not much ""updated"" guides on the internet when I tried to search. For example I learned that the newer versions of kafka can avoid using zookeeper (and some users find zookeeper a pain in the ass so that's good, right?) but there's basically zero guides to setting up kafka without using zookeeper. Yes, there's the official docs and I tried it but it only teaches the super basic setup (no connections to anything).

I know this sounds so whiny but it's not like I'm looking to be spoon-fed. I just want to know how you guys learned streaming and would be glad to know your tips on this. Thank you!",2,0.63,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yi48n/having_a_hard_time_selfstudying_kafka/,march-2020
13,Data engineering student looking to setup streaming exercise with Kafka(confluence),"The title says almost everything my goals are to cover the basics of setting up data streaming using Kafka through confluence, any advice on what exercises would fit this or any tips for setup. I am just starting out and heard Kafka was a pain to work with.",2,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16zb1ah/data_engineering_student_looking_to_setup/,wolfmaster58
14,"Speaking with head of data engineering for career pivot, what should I ask?","**Background:**   
I am an analyst in an oil &amp; gas company who is interested in data engineering. Been working for about 10 years, most of it not related my current role as an analyst but specific to my industry. My background is not computer science, but chemical engineering. I've been doing a lot more python &amp; SQL. I'm getting much more used to the AWS tech stack (Glue, s3, redshift). 

I was in a meeting with him and reached out after the meeting to tell him I am interested in data engineering. I asked if he'd be willing to talk to me. He nicely agreed.

**Why I'm nervous:**

I don't want to waste this opportunity. I am used to the corporate networking, but I'm trying to sell myself and pivot into something quite frankly I don't have a lot of expertise in. One of my concerns is that to get a role I've heard they require testing and a technical interview (coding interview) even for internal. So I'm mostly scared that I won't be able to handle the technical parts!

**Here are some questions I was thinking about**

* Tell me about yourself (always gotta start with the classics)
* Are there any opportunities to practice or learn more of the DE side?
* Is there any advice you'd give to someone without a CS background to demonstrate their capability?

Any other advice, questions, or a reminder of ""hey you're overthinking this""",4,0.84,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16zafs9/speaking_with_head_of_data_engineering_for_career/,chlor8
15,How to apply data engineering as an analyst,"Hey everyone,  


Currently an analyst looking to implement data engineering practices in my work. I've realized within our PowerBI workspace a lot of our reports run duplicate queries against the data warehouse (although sometimes out data isn't in the warehouse and we have to get it from external sources via r scripts). From reading around it seems like PowerBI data flows might be a solution for this but also they seem to scale poorly would it make sense to go about creating a data mart to subset common data sets to improve the workflow for the other analysts on my team? Or does anyone else have idea's for a scalable solution for creating various pipelines from our data warehouse/ external sources (csv's, api's)   
",3,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z668s/how_to_apply_data_engineering_as_an_analyst/,jotama0121
16,Any remote location jobs?,"I would really like to find a position that requires me to be out in the sticks. I know I can do remote work but even better would be something that allows me to interact as time, weather and etc permit. I'm mostly a data engineer but also have quite a bit of dev ops experience which might actually help me find something. Any ideas?",2,0.75,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z4ol2/any_remote_location_jobs/,SoggyChilli
17,Data Completeness: To Stream or Not to Stream,,2,1.0,2023-10-04,https://tobikodata.com/data-completeness.html,s0ck_r4w
18,Apache Beam Question,"Could one senior data engineer with solid experience setup Apache Beam and real-time streaming from scratch for a startup organisation within a reasonable timeframe? Eg., 8-12 weeks, with earlier prototypes?
Just getting a handle on the complexity compared to a non-streaming data warehouse like dbt, which I would have said definitely yes.

Any thoughts or advice on complexities jumping to streaming and Apache Beam is much appreciated.

Thanks!!",2,0.75,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16ysa9g/apache_beam_question/,pbower2049
19,Streaming data from MySQL to Azure Event Hub,"Hi All. I have a requirement to read data from on-prem MySQL database to Azure Event Hub. This data will be later used in Power BI. 

What is the best way to get MySQL data to Event Hub in streaming fashion? I read that we can use bin logs of MySQL, which means I need to run a python process on on-prem system that can push data to Event Hub. Is there any other ways which are better? ",2,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yqrwy/streaming_data_from_mysql_to_azure_event_hub/,inglocines
20,Introductive ML lectures as DE,"Hi,
Do you have some beginner resources (blog posts, books, videos) to start learning ML terminology and connection points with data engineering ?",2,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16ypyoo/introductive_ml_lectures_as_de/,ultimaRati0
21,Data Engineering Acticities,"What exactly is involved in data engineering?

Are data engineers supposed to design data collection instruments?",2,0.67,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16ykk2c/data_engineering_acticities/,Educational-Rise6486
22,Is the title really industry agnostic?,"What are your opinions on how a data engineer position varies between industries? I bet it's hard to generalise, but I'm sure there's some that are more likely to be chill and slow, some that can invest in the shiny tech etc. Where would you never send your resume to? Where would you look if you wanted a career jump? Hope to hear your hypotheses",1,0.6,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yzlo4/is_the_title_really_industry_agnostic/,prsrboi
23,Powercenter ETL career,"Hello guys! I am working in a field where Pentaho ETL is used. So, i got some curiousity to work in ETL. Now, I want to leave my domain and learn the Powercenter ETL. May I choose a career in Powercenter ETL? How does the future look on this domain? May i know the scope, insights of Powercenter ETL?",1,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yvknm/powercenter_etl_career/,tamizhiniyan
24,How do you locally test python code running in airflow?,"We have lil pipeline at work, and it turns out my coworker just goes into the cloud composer interface and manually uploads python files to become the new DAGs.

He writes the code in a jupyter notebook, tests it a few times, then saves it to a `.py` file and uploads it straight into production.

Is this... normal? 

I'm not a data engineer, just a concerned friend. Obviously there is no version control this way, and I'm sure it makes things harder to test. 

I read [this guide](https://cloud.google.com/composer/docs/dag-cicd-integration-guide) on getting CI/CD set up with cloud composer, but it seems a little overkill. Maybe I'm underestimating the effort needed to set up a good airflow environment, but my impression is we started using cloud composer (over a self-managed airflow instance) because it's pretty plug-n-play.

Any ideas? Do you cloud composer users out there use a process like in that guide?",1,1.0,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yuget/how_do_you_locally_test_python_code_running_in/,chamomile-crumbs
25,How to start a data project," 

Hi There   
 

I’m trying to create documentation to map all necessary tasks before starting a Data Platform Project.   
 

The idea is to create a template\\guide to help the new teammates to start a data project. Can you guys help me to list some bullet points?   
 ",1,0.67,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16ys2j0/how_to_start_a_data_project/,yeager_doug
26,Web scraping applications in data engineering,"Web scraping is a data collection technique that allows users to extract data from websites in an automated way. This technique is widely used in several areas, including data engineering.",0,0.43,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16zaj0s/web_scraping_applications_in_data_engineering/,adabbledragon85
27,Interview coding problem ideas,"I was tasked with coming up with a new interview process and I'd like to use coderpad or Hackerrank for a pair programming exercise. I don't want to use Leetcode problems because it doesn't tell me much about the candidates coding skills and it weeds out potentially good candidates from non-CS backgrounds (which is most DEs). 

Has anyone implemented something like this before? How did you go about it? I guess it should be somewhat related to the business, but that's not too straightforward with lengthy DE pipelines. The problem should be doable in 30 mins and only use the standard library.",0,0.5,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16z3ym8/interview_coding_problem_ideas/,Agitated_Ad_1108
28,Advice on Azure Data Engineering Career,"I'm planning to switch my career to Azure data engineering. In process I did a course on ADF and did hands-on in dataflows, pipelines etc. As a next step should I learn Azure Synapse analytics, Pyspark or Azure data bricks and Pyspark? I'm bit clueless as to choose which one? I have 13years experience in Oracle data integrator, etl, data warehousing and sql. Please guide.",0,0.5,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yv1yl/advice_on_azure_data_engineering_career/,gonegura
29,Advice for landing a job in the US,"Hi all,

I currently work in the UK for a fully remote startup as a Data Engineer. 

I'm currently thinking about moving to the US for a change of scenery / fresh start. 

Does anyone have any advice on which type of companies to target? How to secure a visa etc.? Does anyone have any experience with making this move?

High level CV:  


* British and Irish dual national
* PhD in Engineering from Oxbridge 
* 2 years of experience as Python Engineer and 1 as a Data Engineer
* Certified AWS Solutions Architect and AWS Data Analyst 

My preference would be to work in Energy Tech and in a hybrid role but those aren't hard requirements. 

Thanks in advance for any advice

&amp;#x200B;",0,0.17,2023-10-04,https://www.reddit.com/r/dataengineering/comments/16yuxds/advice_for_landing_a_job_in_the_us/,mentalwall
